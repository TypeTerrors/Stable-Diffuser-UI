services:
  py:
    build:
      context: ./py
      dockerfile: Dockerfile
    container_name: img-generator-py
    env_file: .env
    environment:
      MODEL_PATH: ${PY_MODEL_PATH}
      PYTHONUNBUFFERED: "1"
      PYTHONPATH: "/app"
    volumes:
      - ./py:/app
      - ./py/models:${MODEL_MOUNT_PATH:-/workspace/models}:ro
      - ./py/loras:${LORA_MOUNT_PATH:-/workspace/loras}:ro
    working_dir: /app
    command: python main.py
    ports:
      - "${PY_PORT}:50051"
    healthcheck:
      test: ["CMD", "python", "-c", "import grpc; ch=grpc.insecure_channel('localhost:50051'); grpc.channel_ready_future(ch).result(timeout=2); ch.close()"]
      interval: 30s
      timeout: 5s
      retries: 3
    shm_size: 1gb
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  be:
    build:
      context: ./be
      dockerfile: Dockerfile
    container_name: img-generator-be
    depends_on:
      py:
        condition: service_healthy
    env_file: .env
    environment:
      APP_ENV: ${APP_ENV}
      API_PORT: ${API_PORT}
      API_ALLOWED_ORIGINS: ${API_ALLOWED_ORIGINS}
      RPC_PEER: ${RPC_PEER}
      RPC_PORT: ${RPC_PORT}
    volumes:
      - ./py/models:${MODEL_MOUNT_PATH:-/workspace/models}:ro
      - ./py/loras:${LORA_MOUNT_PATH:-/workspace/loras}:ro
    ports:
      - "${API_PORT}:${API_PORT}"

  fe:
    image: node:20
    container_name: img-generator-fe
    working_dir: /app
    volumes:
      - ./fe:/app
      - /app/node_modules
    env_file: .env
    environment:
      NEXT_PUBLIC_BASE_URL: ${NEXT_PUBLIC_BASE_URL}
      NEXT_PUBLIC_API_BASE_URL: ${NEXT_PUBLIC_API_BASE_URL}
      NODE_ENV: development
    command: sh -c "npm install && npm run dev -- --hostname 0.0.0.0 --port 3000"
    ports:
      - "${FE_PORT}:3000"
    depends_on:
      be:
        condition: service_started
